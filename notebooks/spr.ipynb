{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def open_file(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as infile:\n",
    "        return infile.read()\n",
    "    \n",
    "def save_file_to_json(filepath, content):\n",
    "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(content, outfile)\n",
    "\n",
    "def save_file(filepath, content):\n",
    "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(input_text):\n",
    "    \"\"\"\n",
    "    Cleans the input text by removing or replacing special characters to make it JSON-safe.\n",
    "\n",
    "    :param input_text: The raw input text to clean.\n",
    "    :return: A cleaned version of the text.\n",
    "    \"\"\"\n",
    "    # Replace problematic characters\n",
    "    # Replace unusual unicode characters with a placeholder (like empty space or appropriate character)\n",
    "    cleaned_text = input_text.encode('ascii', 'ignore').decode('ascii')  # Remove non-ASCII characters\n",
    "    cleaned_text = re.sub(r'[\\[\\]{}]', '', cleaned_text)  # Remove brackets\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # Replace multiple whitespace with a single space\n",
    "\n",
    "    return cleaned_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, RateLimitError\n",
    "import backoff\n",
    "from halo import Halo\n",
    "import time\n",
    "\n",
    "# setup the OpenAI Client\n",
    "client = OpenAI()\n",
    "\n",
    "@backoff.on_exception(backoff.expo, RateLimitError)\n",
    "def chat(**kwargs):\n",
    "    try:\n",
    "        #spinner = Halo(text=\"Packing SPR...\", spinner=\"dots\")\n",
    "        #spinner.start()\n",
    "        # print(kwargs)\n",
    "\n",
    "        start_time = time.time()  # Record the start time\n",
    "        response = client.beta.chat.completions.parse(**kwargs)\n",
    "        end_time = time.time()  # Record the end time\n",
    "\n",
    "        elapsed_time = end_time - start_time  # Calculate the elapsed time in seconds\n",
    "        minutes, seconds = divmod(\n",
    "            elapsed_time, 60\n",
    "        )  # Convert seconds to minutes and seconds\n",
    "        formatted_time = (\n",
    "            f\"{int(minutes)} minutes and {seconds:.2f} seconds\"  # Format the time\n",
    "        )\n",
    "\n",
    "        text = response.choices[0].message.parsed.text\n",
    "        model = response.model\n",
    "        tokens = response.usage\n",
    "\n",
    "        #spinner.stop()\n",
    "\n",
    "        return text, model, tokens, formatted_time\n",
    "    except Exception as yikes:\n",
    "        print(f'\\n\\nError communicating with OpenAI: \"{yikes}\"')\n",
    "        exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydantic import BaseModel\n",
    "\n",
    "def spr_pack(input_dir: str, output_dir: str):\n",
    "\n",
    "    class ModelResponse(BaseModel):\n",
    "        text: str\n",
    "        model: str\n",
    "\n",
    "    # Create conversation\n",
    "    conversation = list()\n",
    "    conversation.append(\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": open_file(\"../prompts/spr_pack.xml\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        print(filename)\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(input_dir, filename), \"r\", encoding=\"UTF-8\") as f:\n",
    "                text = f.read()\n",
    "                #print(text)\n",
    "                conversation.append(\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [{\"type\": \"text\", \"text\": clean_text(text)}],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                #print(conversation)\n",
    "\n",
    "                #save_file_to_json(\"test.json\", conversation)\n",
    "\n",
    "                text, model, tokens, formatted_time = chat(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=conversation,\n",
    "                    max_completion_tokens=2000,\n",
    "                    temperature=1,\n",
    "                    response_format=ModelResponse,\n",
    "                )\n",
    "\n",
    "                save_file(f\"{output_dir}/{filename}.md\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spr_pack(\"../docs/northside/split/\", \"../docs/northside/split/spr/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
